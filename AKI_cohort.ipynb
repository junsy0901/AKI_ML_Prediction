{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c01e9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.preprocessing import LabelEncoder  # 추가된 라이브러리\n",
    "\n",
    "# 1. 데이터 로드\n",
    "file_path = 'AKI_cohort.csv'  # 파일 경로 확인\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4b4a570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전처리 시작: 총 51개 변수, 811명 환자 데이터 로드됨.\n",
      "범주형(문자열) 변수 변환 중: ['gender', 'race', 'insurance', 'admission_type']\n",
      "결측률 20%를 초과하는 변수가 없습니다. (모두 유지)\n",
      "남은 변수 개수: 51개\n",
      "결측치 대체(MICE) 진행 중... (데이터 크기에 따라 시간이 소요될 수 있습니다)\n",
      "결측치 대체 완료.\n",
      "==================================================\n",
      "전처리 완료! 파일 저장됨: Processed_MIMIC_Data.csv\n",
      "최종 데이터 크기: (811, 55)\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\junsy\\miniconda3\\envs\\aki-project\\Lib\\site-packages\\sklearn\\impute\\_iterative.py:895: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# ID 컬럼과 결과 변수(Target) 분리\n",
    "identifiers = ['subject_id', 'hadm_id', 'stay_id']\n",
    "target_col = 'aki_outcome'\n",
    "\n",
    "# 분석에 사용할 변수들만 선택 (ID 및 Target 제외)\n",
    "X = df.drop(columns=identifiers + [target_col], errors='ignore')\n",
    "y = df[target_col]\n",
    "\n",
    "print(f\"전처리 시작: 총 {X.shape[1]}개 변수, {X.shape[0]}명 환자 데이터 로드됨.\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 2. 범주형 변수 숫자 변환 (Label Encoding)\n",
    "# Gender, Race 등 문자열 데이터를 숫자로 변환합니다.\n",
    "# ==============================================================================\n",
    "object_cols = X.select_dtypes(include=['object']).columns\n",
    "if len(object_cols) > 0:\n",
    "    print(f\"범주형(문자열) 변수 변환 중: {object_cols.tolist()}\")\n",
    "    le = LabelEncoder()\n",
    "    for col in object_cols:\n",
    "        # 결측치가 섞여 있을 경우를 대비해 문자열로 변환 후 인코딩\n",
    "        X[col] = le.fit_transform(X[col].astype(str))\n",
    "else:\n",
    "    print(\"범주형(문자열) 변수가 없습니다.\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 3. 결측치 처리 (Missing Value Processing) - 논문 방법론 적용\n",
    "# ==============================================================================\n",
    "\n",
    "# 3-1. 결측률 20% 초과 변수 제거 [논문 p.3, Data cleaning 섹션]\n",
    "# SQL로 이미 최종 변수를 뽑았더라도, 우리 데이터에서 결측이 너무 심하면 제외하는 것이 맞습니다.\n",
    "missing_threshold = 0.20\n",
    "missing_series = X.isnull().mean()\n",
    "drop_columns = missing_series[missing_series > missing_threshold].index.tolist()\n",
    "\n",
    "if len(drop_columns) > 0:\n",
    "    X_filtered = X.drop(columns=drop_columns)\n",
    "    print(f\"⚠️ 결측률 20% 초과로 제거된 변수 ({len(drop_columns)}개): {drop_columns}\")\n",
    "else:\n",
    "    X_filtered = X\n",
    "    print(\"결측률 20%를 초과하는 변수가 없습니다. (모두 유지)\")\n",
    "\n",
    "print(f\"남은 변수 개수: {X_filtered.shape[1]}개\")\n",
    "\n",
    "# 3-2. 다중 대체 (MICE) 적용 [논문 p.3, Data cleaning 섹션]\n",
    "# 결측값을 다른 변수들과의 상관관계를 이용해 채워 넣습니다.\n",
    "print(\"결측치 대체(MICE) 진행 중... (데이터 크기에 따라 시간이 소요될 수 있습니다)\")\n",
    "imputer = IterativeImputer(max_iter=10, random_state=42)\n",
    "X_imputed_array = imputer.fit_transform(X_filtered)\n",
    "\n",
    "# 컬럼명과 인덱스 복원\n",
    "X_final = pd.DataFrame(X_imputed_array, columns=X_filtered.columns, index=X_filtered.index)\n",
    "print(\"결측치 대체 완료.\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 4. 최종 데이터셋 저장\n",
    "# RFE 단계 생략: SQL에서 추출한 변수 목록을 최종 변수로 확정\n",
    "# ==============================================================================\n",
    "\n",
    "# ID, Target, 전처리된 Features를 합쳐서 저장\n",
    "final_df = pd.concat([df[identifiers], df[[target_col]], X_final], axis=1)\n",
    "\n",
    "output_filename = 'Processed_MIMIC_Data.csv'\n",
    "final_df.to_csv(output_filename, index=False)\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(f\"전처리 완료! 파일 저장됨: {output_filename}\")\n",
    "print(f\"최종 데이터 크기: {final_df.shape}\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24f0e30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aki-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
